# stratgen v1.2

**Cross-sectional factor analysis on a multi-ticker universe.**

v1.2 adds a parallel `analyze` pipeline for cross-sectional alpha factors — the ~50 WorldQuant alphas that use `rank()` (cross-sectional ranking) and were previously excluded from the single-ticker pipeline. Instead of backtesting one ticker with entry/exit signals, cross-sectional analysis ranks factors across a universe of sector ETFs and evaluates them using standard academic metrics: Information Coefficient, tercile portfolios, and return monotonicity.

```
python -m stratgen discover    # (v1.1) time-series factors on SPY
python -m stratgen optimize    # (v1.1) grid search on train/test split
python -m stratgen signals     # (v1.1) LONG/FLAT signals
python -m stratgen analyze     # (v1.2) cross-sectional analysis on sector ETFs
python -m stratgen status      # Alpaca account status
```

---

## Table of Contents

1. [What Changed from v1.1](#what-changed-from-v11)
2. [Cross-Sectional Analysis](#cross-sectional-analysis)
3. [Universe](#universe)
4. [Factor Knowledge Base](#factor-knowledge-base)
5. [Architecture](#architecture)
6. [Pipeline Stages](#pipeline-stages)
7. [Installation](#installation)
8. [Usage](#usage)
9. [Data Formats](#data-formats)
10. [Evaluation Metrics](#evaluation-metrics)
11. [Design Decisions](#design-decisions)
12. [Limitations](#limitations)

---

## What Changed from v1.1

| Aspect | v1.1 | v1.2 |
|--------|------|------|
| **Factor count** | 115 (time-series only) | 133 (115 time-series + 18 cross-sectional) |
| **Ticker universe** | SPY only | SPY (time-series) + 11 sector ETFs (cross-sectional) |
| **Analysis type** | Single-ticker backtest | + Cross-sectional ranking and portfolio analysis |
| **New modules** | — | `universe.py`, `cross_section.py`, `factor_analyze.py` |
| **New command** | — | `python -m stratgen analyze` |
| **Data caching** | yfinance download each run | Parquet cache under `data/universe/` (24h TTL) |
| **Evaluation metrics** | Sharpe, drawdown, return, trades | + IC, IC t-stat, monotonicity, long-short spread |
| **Dependencies** | — | + scipy, pyarrow |
| **Results file** | — | + `results_factors_xs.json` |

### What stayed the same

The existing time-series pipeline (discover → optimize → signals) is completely untouched. The `analyze` command is a parallel path that operates on a separate set of factor docs in `factors/cross_sectional/`.

---

## Cross-Sectional Analysis

Cross-sectional factors rank stocks relative to each other at each point in time. Unlike time-series factors that generate buy/sell signals for a single ticker, cross-sectional factors answer: "Which stocks in the universe are relatively strong/weak according to this signal?"

### How it works

```
Factor doc (.md)            "WQ-006: -1 * correlation(rank(open), rank(volume), 10)"
      │
      ▼
Deterministic parse          FactorSpec(name="WQ-006", formula="...",
      │                                factor_type="cross_sectional")
      ▼
LLM: generate code           def compute_alpha(universe_data, **params) -> DataFrame
      │                      (cached in results_factors_xs.json)
      ▼
Compute alpha                 DataFrame(index=dates, columns=tickers, values=alpha)
      │
      ▼
Rank cross-sectionally        alpha.rank(axis=1, pct=True) at each date
      │
      ▼
Form tercile portfolios       Top 4, Mid 3, Bottom 4 ETFs
      │
      ▼
Evaluate                      IC=0.02, t=1.8, Mono=0.5, L/S=-0.0001 → MARGINAL
```

### Key difference from time-series pipeline

| Aspect | Time-series (discover) | Cross-sectional (analyze) |
|--------|----------------------|--------------------------|
| **Code output** | `class GeneratedStrategy(Strategy)` | `def compute_alpha(universe_data) -> DataFrame` |
| **Data shape** | 1D array (one ticker) | 2D panel (dates × tickers) |
| **Signal** | alpha > 0 → LONG | Relative rank across tickers |
| **Evaluation** | Sharpe, drawdown, trades | IC, monotonicity, L/S spread |
| **Engine** | backtesting.py | Pure pandas (no backtesting.py) |

---

## Universe

11 S&P 500 sector ETFs provide a clean, liquid universe for cross-sectional analysis:

| ETF | Sector |
|-----|--------|
| XLB | Materials |
| XLC | Communication Services |
| XLE | Energy |
| XLF | Financials |
| XLI | Industrials |
| XLK | Technology |
| XLP | Consumer Staples |
| XLRE | Real Estate |
| XLU | Utilities |
| XLV | Health Care |
| XLY | Consumer Discretionary |

**Data start: 2019-01-01** — XLC (Communication Services) launched June 2018. Starting from 2019 gives all 11 ETFs full coverage.

**Caching**: OHLCV data is downloaded via yfinance and cached as Parquet files under `data/universe/`. Re-download if older than 24 hours.

---

## Factor Knowledge Base

### Time-series factors (unchanged from v1.1)

115 factors across 7 categories under `factors/`:

| Category | Count |
|----------|-------|
| Momentum | 34 |
| Volume-Price | 25 |
| Mean Reversion | 15 |
| Volatility | 13 |
| Price Channel | 13 |
| Trend | 12 |
| Composite | 3 |

### Cross-sectional factors (new in v1.2)

18 rank-based factors under `factors/cross_sectional/`:

| Factor | Formula | Description |
|--------|---------|-------------|
| WQ-001 | `rank(ts_argmax(SignedPower(...), 5)) - 0.5` | Ranked conditional volatility argmax |
| WQ-006 | `-1 * correlation(rank(open), rank(volume), 10)` | Open-volume rank correlation |
| WQ-008 | `-1 * rank(delta(midpoint, 4) - delta(midpoint, 8))` | Ranked midpoint acceleration |
| WQ-010 | `rank(where(ts_min(...) > 0, ..., ...))` | Conditional momentum/reversal |
| WQ-013 | `-1 * rank(covariance(rank(close), rank(volume), 5))` | Close-volume rank covariance |
| WQ-016 | `-1 * rank(covariance(rank(high), rank(volume), 5))` | High-volume rank covariance |
| WQ-022 | `-1 * delta(corr(high, vol, 5), 5) * rank(stddev)` | High-vol correlation change |
| WQ-030 | `rank(directional_persistence) * vol_ratio` | Directional persistence × volume |
| WQ-033 | `rank(-1 * (1 - open/close))` | Ranked intraday return |
| WQ-037 | `rank(corr(delay(oc,1), close, 200)) + rank(oc)` | Long-term corr + intraday |
| WQ-044 | `-1 * correlation(high, rank(volume), 5)` | High vs ranked volume |
| WQ-045 | `-1 * rank(sma(delay(close,5),20)) * corr * rank(corr)` | Triple-factor product |
| WQ-090 | `-1 * rank(serial_corr) * rank(sma_deviation)` | Serial corr × SMA deviation |
| WQ-091 | `-1 * rank(close - max(close,5)) * rank(corr(vol,low))` | Distance from max × vol-low corr |
| WQ-099 | `-1 * rank(covariance(rank(close), rank(volume), 5))` | Close-volume rank cov (variant) |
| WQ-115 | `rank(corr1) * rank(corr2)` | Product of two ranked correlations |
| WQ-136 | `rank(delta(returns, 3)) * corr(open, vol, 10) * -1` | Return accel × open-vol corr |
| WQ-157 | `min(product(rank(rank(log(...))), 1), 5) + ts_rank(...)` | Deeply nested rank composition |

These 18 are the "RANK-only" alphas from the excluded set — they use only `rank()` with OHLCV data (no VWAP, AMOUNT, IndNeutralize, or market cap).

### Cross-sectional factor doc format

Same as time-series, plus a `## Type` field:

```markdown
# WQ-006: Open-volume rank correlation

## Formula
-1 * correlation(rank(open), rank(volume), 10)

## Interpretation
Negative correlation between cross-sectional ranks of open price and volume.

## Parameters
| Param | Default | Range |
|-------|---------|-------|
| lookback | 10 | [5, 20] |

## Type
cross_sectional

## Category
cross_sectional

## Source
WorldQuant Alpha#006 (Kakushadze 2015)
```

---

## Architecture

```
src/stratgen/
├── cli.py              ─── Unified entry point, argparse subcommands
├── paths.py            ─── Path constants (DATA_DIR, XS_FACTORS_DIR, etc.)
├── core.py             ─── FactorSpec, llm_call(), TS + XS codegen, evaluate()
├── universe.py         ─── Sector ETF download, Parquet cache, build_panel()
├── cross_section.py    ─── Ranking, portfolios, IC, monotonicity, XS evaluation
├── factor_discover.py  ─── TS: parse → codegen → backtest → evaluate
├── factor_optimize.py  ─── TS: grid search with train/test split
├── factor_signals.py   ─── TS: signal generation from top factors
├── factor_analyze.py   ─── XS: parse → codegen → rank → evaluate
└── trade.py            ─── Alpaca: account status
```

### Module dependency graph

```
cli.py
  ├── factor_discover.py  →  core.py, paths.py
  ├── factor_optimize.py  →  core.py, paths.py
  ├── factor_signals.py   →  core.py, paths.py
  ├── factor_analyze.py   →  core.py, paths.py, universe.py, cross_section.py,
  │                           factor_discover.py (parse_factor_doc, load/save_results)
  └── trade.py            →  (alpaca-py)
```

### Key data types

**FactorSpec** — now includes `factor_type`:

```python
@dataclass
class FactorSpec:
    name: str                    # "WQ-006: Open-volume rank correlation"
    formula: str                 # "-1 * correlation(rank(open), rank(volume), 10)"
    interpretation: str          # "Negative open-volume rank correlation"
    params: dict                 # {"lookback": 10}
    param_ranges: dict           # {"lookback": [5, 20]}
    category: str                # "cross_sectional"
    source: str                  # "WorldQuant Alpha#006"
    factor_ref: str              # "factors/cross_sectional/wq_006.md"
    factor_type: str             # "cross_sectional"
```

### XS evaluation verdicts

| Verdict | Criteria |
|---------|----------|
| **PASS** | \|IC\| >= 0.03, \|t-stat\| >= 2.0, monotonicity >= 0.5, L/S spread > 0 |
| **MARGINAL** | \|IC\| >= 0.01, monotonicity >= 0.5, but doesn't meet all PASS thresholds |
| **FAIL** | \|IC\| < 0.01 or monotonicity < 0.5 |
| **ERROR** | Exception during codegen or evaluation |

---

## Pipeline Stages

### Stage: Analyze (new in v1.2)

**Command:** `python -m stratgen analyze [--reset] [--provider openai|anthropic] [--n-groups 3]`

Processes all 18 cross-sectional factor docs:

1. **Download universe** — 11 sector ETFs via yfinance, cached as Parquet.
2. **Parse** — Regex-based extraction of FactorSpec from `.md` (same parser as discover, now handles `## Type`).
3. **Code generation** — LLM generates a `compute_alpha(universe_data, **params) -> DataFrame` function. Cached in results.
4. **Compute alpha** — Run `compute_alpha` on the universe data. Output: DataFrame(dates × tickers).
5. **Rank** — `alpha.rank(axis=1, pct=True)` at each date.
6. **Form portfolios** — Group tickers into N groups by rank. Compute equal-weight next-day returns per group.
7. **Information Coefficient** — Daily Spearman correlation of alpha vs next-day returns across tickers.
8. **Monotonicity** — Fraction of adjacent groups with correct return ordering.
9. **Evaluate** — Apply PASS/MARGINAL/FAIL thresholds.
10. **Save** — Results saved to `results_factors_xs.json` after each factor for resume.

### Existing stages (unchanged)

- **Discover** — `python -m stratgen discover` (115 time-series factors)
- **Optimize** — `python -m stratgen optimize`
- **Signals** — `python -m stratgen signals`
- **Status** — `python -m stratgen status`

---

## Installation

```bash
git clone <repo-url> && cd autonomous_trading
pip install -e .

# With dev tools
pip install -e ".[dev]"
```

**Requirements:** Python 3.10+

**Dependencies:** anthropic, alpaca-py, backtesting, openai, pandas, pyarrow, python-dotenv, scipy, yfinance

---

## Usage

```bash
# Cross-sectional analysis (new in v1.2)
python -m stratgen analyze                    # resume from previous run
python -m stratgen analyze --reset            # start fresh
python -m stratgen analyze --provider anthropic
python -m stratgen analyze --n-groups 5       # quintiles instead of terciles

# Time-series pipeline (unchanged)
python -m stratgen discover
python -m stratgen optimize
python -m stratgen signals --top-n 3
python -m stratgen status
```

---

## Data Formats

### results_factors_xs.json (analyze)

```json
{
  "factor_ref": "factors/cross_sectional/wq_006.md",
  "name": "WQ-006: Open-volume rank correlation",
  "category": "cross_sectional",
  "formula": "-1 * correlation(rank(open), rank(volume), 10)",
  "params": {"lookback": 10},
  "param_ranges": {"lookback": [5, 20]},
  "code": "import pandas as pd\nimport numpy as np\ndef compute_alpha(universe_data, **params):\n...",
  "verdict": "MARGINAL",
  "reasons": ["MARGINAL: |IC| 0.0214 < 0.03"],
  "error": null,
  "metrics": {
    "mean_ic": -0.0214,
    "ic_t_stat": -1.81,
    "monotonicity": 0.5,
    "long_short_spread": -0.0001,
    "group_mean_returns": {"1": 0.0006, "2": 0.0008, "3": 0.0006},
    "n_groups": 3
  }
}
```

---

## Evaluation Metrics

| Metric | What it measures | Good values |
|--------|-----------------|-------------|
| **Information Coefficient (IC)** | Daily Spearman rank correlation between alpha and next-day returns across tickers | \|IC\| >= 0.03 |
| **IC t-statistic** | Statistical significance of IC (is it reliably non-zero?) | \|t\| >= 2.0 |
| **Monotonicity** | Do higher-ranked groups earn higher returns? Fraction of adjacent pairs with correct ordering | >= 0.5 (1.0 = perfect) |
| **Long-short spread** | Mean return of top group minus bottom group | > 0 (positive = factor works) |

### Why terciles?

With only 11 sector ETFs, quintiles would give just 2 ETFs per group — too few for stable estimates. Terciles (top 4, mid 3, bottom 4) provide a better balance. Use `--n-groups 5` with a larger universe later.

---

## Design Decisions

**Why sector ETFs instead of individual stocks?**
Sector ETFs are liquid, don't delist, have stable constituents, and cover all 11 GICS sectors. They're ideal for learning cross-sectional factor behavior without survivorship bias or missing data.

**Why Parquet caching?**
Downloading 11 tickers takes ~10 seconds. Caching as Parquet avoids repeated downloads and provides fast reads. Files expire after 24 hours.

**Why pure functions instead of backtesting.py strategies?**
Cross-sectional factors produce a panel of alpha values (dates × tickers), not entry/exit signals for one ticker. There's no position to backtest — the evaluation is statistical (IC, portfolio sorts).

**Why 18 factors (not all 50+ rank factors)?**
Many rank-based alphas also require VWAP, dollar volume (adv), IndNeutralize, or market cap data that sector ETFs don't readily provide. The 18 selected use ONLY `rank()` with standard OHLCV fields.

**Why separate results file?**
`results_factors_xs.json` is independent of `results_factors.json`. The two pipelines (time-series and cross-sectional) don't share results, keeping concerns separate.

---

## Limitations

- **Small universe (11 ETFs).** Cross-sectional ranking across 11 tickers produces noisy IC estimates. Results will be more meaningful with a larger universe (e.g., S&P 500 constituents).

- **No optimization stage for XS factors.** The `analyze` command evaluates with default params. A future `optimize-xs` command could grid search params like the time-series pipeline.

- **No portfolio construction.** The analysis forms equal-weight portfolios for evaluation but doesn't generate actionable signals or positions.

- **No transaction costs.** Portfolio returns are computed without commissions, slippage, or rebalancing costs.

- **Daily rebalancing assumed.** Tercile portfolios are rebalanced daily, which overstates turnover in practice.

- **Code generation is non-deterministic.** LLM outputs may vary between runs. Cached code mitigates this for repeated evaluations.
