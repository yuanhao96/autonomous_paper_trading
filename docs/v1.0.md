# stratgen v1.0

**Autonomous single-asset trading strategy generation, optimization, and paper trading.**

stratgen takes a curated knowledge base of 92 trading strategy documents, uses an LLM to convert each into executable backtesting code, evaluates them against performance thresholds, optimizes parameters via grid search with out-of-sample validation, and deploys the winners to an Alpaca paper trading account.

The full pipeline runs with five commands:

```
python -m stratgen discover    # knowledge docs → specs → code → backtest → evaluate
python -m stratgen optimize    # grid search on train split, evaluate on test split
python -m stratgen signals     # generate current LONG/FLAT signals
python -m stratgen run         # signals → reconcile → submit orders to Alpaca
python -m stratgen status      # show Alpaca account and positions
```

---

## Table of Contents

1. [How It Works](#how-it-works)
2. [Architecture](#architecture)
3. [Knowledge Base](#knowledge-base)
4. [Pipeline Stages](#pipeline-stages)
5. [Installation](#installation)
6. [Configuration](#configuration)
7. [Usage](#usage)
8. [Data Formats](#data-formats)
9. [Design Decisions](#design-decisions)
10. [Results Summary](#results-summary)
11. [Limitations](#limitations)
12. [Project History](#project-history)

---

## How It Works

stratgen is a knowledge-constrained system. The LLM does not invent arbitrary indicator combinations — it reads documented strategy descriptions and translates them into structured specs and executable code within defined constraints.

```
  Knowledge doc (.md)          "Momentum Effect in Stocks"
        │
        ▼
  LLM: extract spec            StrategySpec(name="Momentum Effect",
        │                                   universe=["SPY"],
        │                                   entry="12-month return > 0",
        │                                   exit="12-month return < 0", ...)
        ▼
  LLM: generate code           class GeneratedStrategy(Strategy): ...
        │
        ▼
  backtesting.py                Backtest(df, GeneratedStrategy, cash=100_000)
        │
        ▼
  Evaluate                      PASS (Sharpe 0.45, 12 trades, -8.2% drawdown)
        │
        ▼
  Optimize (grid search)        Train: 2020–mid-2023 | Test: mid-2023–present
        │
        ▼
  Paper trade (Alpaca)          LONG SPY → BUY 42 shares
```

### Constraints

The backtesting system operates under hard limits that the LLM is informed of:

- **Single ticker only** — no multi-asset portfolios or cross-sectional ranking
- **OHLCV price data only** — no fundamentals, sentiment, or alternative data
- **Daily timeframe** — no intraday
- **Long-only or long/short on one asset**
- **backtesting.py engine** — technical indicators computed from price arrays

Strategies that require multiple tickers (pairs trading) or pure fundamental data are either adapted to a single representative ETF or skipped entirely.

---

## Architecture

```
src/stratgen/
├── cli.py          ─── Unified entry point, argparse subcommands, load_dotenv()
├── paths.py        ─── PROJECT_ROOT, KNOWLEDGE_DIR, result file paths
├── core.py         ─── StrategySpec, llm_call(), codegen, evaluate()
├── spec.py         ─── Knowledge doc → StrategySpec via LLM
├── backtest.py     ─── run_backtest(), run_one() (full single-strategy pipeline)
├── discover.py     ─── Loop over all 92 strategy docs with resume
├── optimize.py     ─── Train/test grid search optimization with resume
└── trade.py        ─── Alpaca: signals, order reconciliation, execution
```

### Module dependency graph

```
cli.py
  ├── discover.py  →  backtest.py  →  spec.py  →  core.py
  │                                              paths.py
  ├── optimize.py  →  core.py, paths.py
  └── trade.py     →  core.py, paths.py
```

All modules import from `core.py` (shared primitives) and `paths.py` (constants). No module has import-time side effects — `load_dotenv()` is called once in `cli.py`.

### Key data types

**StrategySpec** — the central data structure:

```python
@dataclass
class StrategySpec:
    name: str                    # "SMA Crossover"
    knowledge_ref: str           # "knowledge/strategies/momentum/sma-crossover.md"
    universe: list[str]          # ["SPY"]
    timeframe: str               # "1d"
    entry_signal: str            # "SMA(20) crosses above SMA(50)"
    exit_signal: str             # "SMA(20) crosses below SMA(50)"
    stop_loss_pct: float         # 0.02
    position_size_pct: float     # 0.95
    params: dict                 # {"fast_period": 20, "slow_period": 50}
    adaptations: list[str]       # ["Multi-asset → single ETF (SPY)"]
    skipped: str | None          # None or reason for skipping
```

**Verdict** — evaluation result for a backtested strategy:

| Verdict | Criteria |
|---------|----------|
| **PASS** | Sharpe >= 0.3, drawdown >= -30%, return >= 0%, trades >= 3 |
| **MARGINAL** | No hard fails, but doesn't meet all PASS thresholds |
| **FAIL** | Sharpe < 0, drawdown < -50%, return < 0%, or trades < 3 |
| **SKIPPED** | Strategy cannot be adapted to single-ticker OHLCV |
| **ERROR** | Exception during pipeline execution |

---

## Knowledge Base

The knowledge base is a curated collection of 145 markdown documents sourced from QuantConnect's public educational materials, organized into four sections:

| Section | Documents | Content |
|---------|-----------|---------|
| `knowledge/strategies/` | 92 | Trading strategy descriptions with entry/exit rules, parameters, academic references |
| `knowledge/financial-python/` | 14 | Python, NumPy, pandas, statistics, regression, portfolio theory |
| `knowledge/key-concepts/` | 15 | Algorithm architecture, time management, event handling |
| `knowledge/trading-concepts/` | 33 | Indicators, reality modeling, order types, portfolio management |

### Strategy categories

The 92 strategy documents span 10 categories:

| Category | Count | Examples |
|----------|-------|----------|
| Momentum | 26 | 12-month effect, sector rotation, earnings momentum |
| Mean Reversion & Pairs | 13 | PCA stat arb, country ETF pairs, copula methods |
| Factor Investing | 10 | Fama-French, beta, skewness, accrual anomaly |
| Calendar Anomalies | 9 | January effect, pre-holiday, lunar cycle, overnight |
| Technical & Other | 8 | Ichimoku cloud, dual thrust, CAPM alpha |
| Value & Fundamental | 8 | P/E anomaly, CAPE, book-to-market, G-Score |
| Machine Learning | 5 | Naive Bayes, SVM wavelet, temporal CNN |
| Volatility & Options | 5 | VIX prediction, term structure, low-vol effect |
| Commodities | 4 | WTI-Brent spread, gold timing, oil-equity link |
| Forex | 4 | Carry trade, risk premia, dynamic breakout |

The knowledge base is **read-only** — the LLM reads from it but never modifies it.

---

## Pipeline Stages

### Stage 1: Discover

**Command:** `python -m stratgen discover`

Processes all 92 strategy documents through the full pipeline:

1. **Spec extraction** — The LLM reads a strategy markdown file and produces a `StrategySpec` JSON. Strategies requiring multi-asset portfolios are adapted to a single representative ETF where possible, or skipped.

2. **Validation** — Checks that the ticker exists on yfinance, signals are non-empty, and stop-loss is in a reasonable range.

3. **Code generation** — The LLM generates a `GeneratedStrategy` class (subclassing `backtesting.Strategy`) from the spec. The generated code uses `self.I()` for indicators and `self.buy()`/`self.sell()` for orders.

4. **Backtesting** — Runs on 2020–2025 daily OHLCV data from yfinance, with $100k starting capital and 0.1% commission.

5. **Evaluation** — Applies pass/fail thresholds to produce a verdict.

Results are saved to `results_v4.json` after every strategy for resume capability. Re-running the command skips already-processed documents.

### Stage 2: Optimize

**Command:** `python -m stratgen optimize`

Takes PASS and MARGINAL strategies from Stage 1 and optimizes their parameters:

1. **Param range extraction** — The LLM reads the knowledge document again and produces 3–7 discrete values per numeric parameter, grounded in the document's recommendations where possible.

2. **Train/test split** — Data before July 2023 is train; after is test.

3. **Grid search** — `backtesting.py`'s built-in optimizer searches the param space on the train split, maximizing Sharpe ratio (default budget: 200 combinations).

4. **Out-of-sample evaluation** — Best params are evaluated on the test split with the same pass/fail thresholds.

Results are saved to `results_v5.json` with resume support.

### Stage 3: Trade

**Commands:**
- `python -m stratgen signals` — signals only, no orders
- `python -m stratgen run` — signals + order submission
- `python -m stratgen status` — account info

Trading uses the top N strategies (default 5) ranked by test-set Sharpe from Stage 2:

1. **Signal extraction** — For each strategy, re-run a backtest on recent data (2024-01-01 to today). If the last trade is still open (exit time is NaT), the signal is LONG; otherwise FLAT.

2. **Aggregation** — Account equity is divided equally among all strategies. LONG signals accumulate dollar allocations per ticker.

3. **Reconciliation** — Compare desired positions to current Alpaca positions. Compute the share delta for each ticker.

4. **Execution** — Submit market orders (DAY time-in-force) to reach the target allocation.

Run logs are appended to `runs_v6.json`.

---

## Installation

```bash
# Clone and install
git clone <repo-url> && cd autonomous_trading
pip install -e .

# Or with dev tools (ruff, mypy, pytest)
pip install -e ".[dev]"
```

**Requirements:** Python 3.10+

**Dependencies:** anthropic, alpaca-py, backtesting, openai, pandas, python-dotenv, yfinance

---

## Configuration

Create a `.env` file in the project root (see `.env.example`):

```
# At least one LLM provider is required
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...

# Required for signals/run/status commands
ALPACA_API_KEY=PK...
ALPACA_SECRET_KEY=...
```

All API keys are loaded via `python-dotenv` at CLI startup. Alpaca credentials should be for a **paper trading** account.

---

## Usage

### Discover all strategies

```bash
python -m stratgen discover                    # run all (auto-resumes)
python -m stratgen discover --reset            # start fresh
python -m stratgen discover --provider anthropic
```

### Optimize parameters

```bash
python -m stratgen optimize                    # optimize PASS/MARGINAL from discover
python -m stratgen optimize --reset
python -m stratgen optimize --max-tries 500    # increase grid search budget
python -m stratgen optimize --v4-results path/to/results.json
```

### Generate signals

```bash
python -m stratgen signals                     # top 5 strategies, signals only
python -m stratgen signals --top-n 3
```

### Submit orders

```bash
python -m stratgen run                         # signals + Alpaca orders
python -m stratgen run --top-n 3
python -m stratgen run --provider anthropic
```

### Account status

```bash
python -m stratgen status                      # Alpaca positions + equity
```

### Common flags

| Flag | Applies to | Description |
|------|-----------|-------------|
| `--provider {openai,anthropic}` | discover, optimize, signals, run | LLM provider (default: openai) |
| `--reset` | discover, optimize | Ignore previous results, start fresh |
| `--top-n N` | signals, run | Number of top strategies to deploy (default: 5) |
| `--max-tries N` | optimize | Grid search budget per strategy (default: 200) |
| `--v4-results PATH` | optimize, signals, run | Custom path to discover results |
| `--v5-results PATH` | signals, run | Custom path to optimize results |

---

## Data Formats

### results_v4.json (discover)

Array of result objects, one per strategy document:

```json
{
  "knowledge_doc": "/path/to/knowledge/strategies/momentum/strategy.md",
  "name": "Momentum Effect",
  "verdict": "PASS",
  "reasons": ["Sharpe 0.45, 12 trades, dd -8.2%, return 25.3%"],
  "skipped": null,
  "error": null,
  "stats": {
    "Return [%]": 25.3,
    "Sharpe Ratio": 0.45,
    "Max. Drawdown [%]": -8.2,
    "# Trades": 12,
    "Win Rate [%]": 58.3,
    "Buy & Hold Return [%]": 72.8
  },
  "spec": { "name": "...", "universe": ["SPY"], "params": {...}, ... },
  "adaptations": ["Multi-asset ranking → applied to SPY only"]
}
```

### results_v5.json (optimize)

Array of optimization result objects:

```json
{
  "knowledge_doc": "/path/to/strategy.md",
  "name": "Momentum Effect",
  "v4_verdict": "PASS",
  "v4_sharpe": 0.45,
  "v4_params": {"lookback": 252},
  "param_ranges": {"lookback": [126, 189, 252, 315, 378]},
  "optimized_params": {"lookback": 189},
  "train_stats": { ... },
  "test_stats": {
    "Sharpe Ratio": 0.52,
    "Return [%]": 18.1,
    "Max. Drawdown [%]": -6.5,
    "# Trades": 8
  },
  "test_verdict": "PASS",
  "test_reasons": ["Sharpe 0.52, 8 trades, dd -6.5%, return 18.1%"],
  "sharpe_improvement": 0.07,
  "error": null
}
```

### runs_v6.json (trade)

Array of run logs, appended after each `run` command:

```json
{
  "timestamp": "2026-02-28T14:30:00",
  "strategies": ["Strategy A", "Strategy B"],
  "signals": [
    {"ticker": "SPY", "strategy": "Strategy A", "signal": "LONG"},
    {"ticker": "QQQ", "strategy": "Strategy B", "signal": "FLAT"}
  ],
  "orders": [
    {"symbol": "SPY", "side": "buy", "qty": 42, "status": "accepted", "order_id": "..."}
  ],
  "account_equity": 100000.0
}
```

---

## Design Decisions

**Why knowledge-constrained?**
Previous iterations allowed the LLM to freely invent strategies. This produced creative but untestable combinations with no academic grounding. Constraining to documented strategies with known parameter ranges produces reproducible, interpretable results.

**Why single-ticker only?**
backtesting.py operates on a single OHLCV DataFrame. Multi-asset strategies would require a custom backtesting engine — which is the kind of premature infrastructure that killed earlier iterations. The single-ticker constraint is documented, and the LLM adapts multi-asset strategies to representative ETFs where possible.

**Why exec() generated code?**
The LLM produces a Python class that subclasses `backtesting.Strategy`. This class is `exec()`'d at runtime and never persisted to disk. This keeps the pipeline stateless — you can re-run discovery with a different LLM provider and get different (possibly better) code without accumulated cruft.

**Why train/test split at mid-2023?**
The split at 2023-06-30 gives roughly 3.5 years of training data (2020–mid-2023) and 2+ years of test data (mid-2023–present). This is long enough for the optimizer to find meaningful patterns and long enough for out-of-sample validation to be meaningful.

**Why resume by default?**
A full discovery run processes 92 strategies with 2 LLM calls each. This takes hours and costs real money in API fees. Saving after every strategy and skipping already-processed documents on restart is essential for reliability.

**Why equal-weight allocation?**
The paper trading system divides equity equally among the top N strategies. This is the simplest allocation that doesn't require predicting which strategies will perform best going forward — a problem as hard as the original trading problem itself.

---

## Results Summary

From a full discovery + optimization run:

### Discovery (92 strategies)

| Verdict | Count |
|---------|-------|
| PASS | 25 |
| MARGINAL | 12 |
| FAIL | 35 |
| SKIPPED | 10 |
| ERROR | 10 |

27% of strategies passed on the full 2020–2025 backtest period.

### Optimization (37 PASS + MARGINAL candidates)

| Test Verdict | Count |
|-------------|-------|
| PASS | 11 |
| MARGINAL | 2 |
| FAIL | 19 |
| ERROR | 5 |

30% of optimized strategies still pass on the held-out test set (mid-2023 to present), suggesting the optimization is not severely overfitting.

---

## Limitations

- **No portfolio-level risk management.** Each strategy trades independently. There is no cross-strategy correlation analysis, no portfolio-level stop-loss, and no maximum drawdown circuit breaker.

- **Signal extraction is approximate.** Current signals are inferred by checking whether the last trade in a backtest is still open. This works for trend-following strategies but may miss signals in strategies with complex entry/exit logic.

- **Code generation is non-deterministic.** Even at temperature=0, LLM outputs can vary. Two runs of `discover` may produce different strategy code for the same knowledge document. Generated code is not cached or versioned.

- **No intraday or multi-asset.** The system is architecturally limited to daily-bar, single-ticker strategies. Extending to intraday or multi-asset would require replacing backtesting.py.

- **Parameter ranges are LLM-suggested.** The grid search values come from an LLM reading the knowledge document. These are usually reasonable but occasionally miss important ranges or include irrelevant parameters.

- **Market orders only.** The Alpaca integration uses market orders with DAY time-in-force. There is no limit order support, no VWAP, and no order management beyond simple reconciliation.

---

## Project History

This is the third attempt at building an autonomous trading system. The key insight that made it work: **constrain the LLM to documented strategies instead of letting it invent freely, and build incrementally instead of designing a grand architecture upfront.**

| Attempt | What happened |
|---------|--------------|
| v1 (`autonomou_evolving_investment`) | Unbounded strategy space + custom infrastructure. The LLM produced creative but unverifiable strategies. Too much infrastructure was built before anything worked end-to-end. |
| v2 (this repo, prior code) | Over-engineered multi-stage pipeline with too many abstractions. Pipeline stages were designed before any stage worked individually. |
| v3 (this repo, current) | Incremental build: each version replaced one manual step. v0 proved backtesting.py works, v1 proved LLM codegen works, v2 added spec extraction, v3 added evaluation, v4 automated discovery, v5 added optimization, v6 added paper trading. Now packaged as `stratgen` v1.0. |

### Build sequence

| Step | What was automated | Insight |
|------|-------------------|---------|
| v0 | Nothing — hand-written SMA crossover | Prove backtesting.py works with yfinance data |
| v1 | Code generation from a hardcoded spec | Prove LLM can produce valid backtesting.py classes |
| v2 | Spec extraction from knowledge docs | Prove LLM can read a strategy description and produce a structured spec |
| v3 | Evaluation with pass/fail thresholds | Remove human judgment from the evaluate step |
| v4 | Full discovery loop over all 92 docs | Scale to the entire knowledge base with resume support |
| v5 | Parameter optimization via grid search | Tune within documented bounds using train/test validation |
| v6 | Paper trading via Alpaca | Close the loop: knowledge → signals → real orders |
